/**
 * Vertex AI OCR Service
 *
 * Vertex AI + Context Cacheã‚’ä½¿ç”¨ã—ãŸOCRå®Ÿè¡Œ
 * - ADCï¼ˆApplication Default Credentialsï¼‰èªè¨¼
 * - Context Cacheæ´»ç”¨ï¼ˆSystem Instructionå«ã‚€ï¼‰
 * - ã¹ãç­‰æ€§ç¶­æŒï¼ˆPhase 6.2ã¨åŒç­‰ï¼‰
 */

import { VertexAI } from '@google-cloud/vertexai';
import { getOrCreateCache } from './cache_manager_vertex';
import type { AIIntermediateOutput } from '../gemini/schemas';

/**
 * Vertex AI OCRå®Ÿè¡Œ
 *
 * @param imageFile - File objectï¼ˆNode.jsç’°å¢ƒï¼‰
 * @param clientId - ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆID
 * @param projectId - GCPãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆID
 * @param location - ãƒªãƒ¼ã‚¸ãƒ§ãƒ³
 * @returns AIIntermediateOutput
 */
export async function executeOCRVertex(
    imageBase64: string,
    mimeType: string,
    clientId: string = 'CL-001',
    projectId: string = 'sugu-suru',
    location: string = 'asia-northeast1'
): Promise<AIIntermediateOutput> {
    console.log(`ğŸ” [Vertex] OCRå®Ÿè¡Œé–‹å§‹: clientId=${clientId}`);

    // ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«ï¼ˆå®šæ•°ï¼‰
    const MODEL_NAME = 'gemini-2.5-flash';

    // Context Cacheå–å¾—
    const cacheInfo = await getOrCreateCache({
        client_id: clientId,
        master_file_path: 'master_data.txt', // Phase 6.3: å›ºå®šå€¤
        projectId,
        location,
        model_name: MODEL_NAME  // ãƒ¢ãƒ‡ãƒ«åã‚’æ¸¡ã™
    });

    console.log(`[Vertex] Cacheå–å¾—å®Œäº†: ${cacheInfo.cacheName}`);

    // Vertex AIå‘¼ã³å‡ºã—
    const responseText = await callVertexAI(
        imageBase64,
        mimeType,
        cacheInfo.cacheName,
        projectId,
        location,
        MODEL_NAME  // ãƒ¢ãƒ‡ãƒ«åã‚’æ¸¡ã™
    );

    // ãƒ¬ã‚¹ãƒãƒ³ã‚¹JSONæŠ½å‡º
    const rawJSON = extractJSONFromResponse(responseText);

    console.log(`âœ… [Vertex] OCRå®Œäº†`);

    return rawJSON as AIIntermediateOutput;
}

/**
 * Vertex AIå‘¼ã³å‡ºã—
 *
 * @param imageBase64 - Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ç”»åƒ
 * @param mimeType - MIMEã‚¿ã‚¤ãƒ—
 * @param cacheName - Cacheåï¼ˆæ–‡å­—åˆ—ï¼‰
 * @param projectId - GCPãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆID
 * @param location - ãƒªãƒ¼ã‚¸ãƒ§ãƒ³
 * @returns ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆ
 */
async function callVertexAI(
    imageBase64: string,
    mimeType: string,
    cacheName: string,
    projectId: string,
    location: string,
    modelName: string  // è¿½åŠ 
): Promise<string> {
    const vertexAI = new VertexAI({
        project: projectId,
        location: location
    });

    try {
        // Cached Contentå‚ç…§ã§ãƒ¢ãƒ‡ãƒ«å–å¾—
        // SDK API: getGenerativeModelFromCachedContent(cachedContent, modelParams?, requestOptions?)
        // ç¬¬1å¼•æ•°ã¯ { name, model } ã‚’æŒã¤ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ç›´æ¥æ¸¡ã™
        const model = vertexAI.preview.getGenerativeModelFromCachedContent({
            name: cacheName,
            model: modelName  // ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
        });

        console.log('ğŸ“¤ [Vertex] Gemini APIå‘¼ã³å‡ºã—ä¸­...');

        // ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆã¹ãç­‰æ€§å‘ä¸Šç‰ˆï¼‰
        const prompt = `ã€ç”»åƒã‚’ç¢ºèªã—ã¦JSONã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‘

ã“ã®ç”»åƒã¯é ˜åæ›¸ã§ã™ã€‚ä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚èª¬æ˜æ–‡ã‚„Markdownã¯ä¸è¦ã§ã™ã€‚

{
  "category": "RECEIPT",
  "vendor": "åº—åï¼ˆç”»åƒã‹ã‚‰æ­£ç¢ºã«èª­ã¿å–ã‚‹ï¼‰",
  "date": "YYYY-MM-DD",
  "total_amount": æ•°å€¤,
  "t_number": "Tç•ªå·ï¼ˆ13æ¡ã®æ•°å­—ãŒã‚ã‚‹å ´åˆï¼‰ã¾ãŸã¯ null",
  "tax_items": [{"rate": 10, "net": ç¨æŠœé¡, "tax": æ¶ˆè²»ç¨}],
  "inferred_category": "å‹˜å®šç§‘ç›®ï¼ˆä¸‹è¨˜ãƒ«ãƒ¼ãƒ«å‚ç…§ï¼‰",
  "explanation": "é¸æŠç†ç”±ï¼ˆ1æ–‡ï¼‰"
}

ã€inferred_categoryæ±ºå®šãƒ«ãƒ¼ãƒ«ï¼ˆå³å®ˆï¼‰ã€‘
1. Tç•ªå·ãƒã‚¹ã‚¿ã«ä¸€è‡´ â†’ Tç•ªå·ãƒã‚¹ã‚¿ã®ç§‘ç›®ã‚’ä½¿ç”¨
2. Tç•ªå·ãƒã‚¹ã‚¿ã«ä¸ä¸€è‡´ã¾ãŸã¯ç„¡ã— â†’ ä»¥ä¸‹ã®åˆ¤æ–­åŸºæº–ã§æ±ºå®š:
   - é£²é£Ÿåº—ã§ã®å€‹äººçš„ãªé£Ÿäº‹ â†’ ã€Œé£²é£Ÿè²»ã€
   - å±…é…’å±‹ãƒ»ãƒãƒ¼ãƒ»æ–™äº­ â†’ ã€Œæ¥å¾…äº¤éš›è²»ã€
   - é‡‘é¡10,000å††ä»¥ä¸Šã®é£²é£Ÿ â†’ ã€Œæ¥å¾…äº¤éš›è²»ã€
   - ãã®ä»–è»½é£Ÿãƒ»ã‚³ãƒ³ãƒ“ãƒ‹ â†’ ã€Œé£²é£Ÿè²»ã€
   - åˆ¤æ–­å›°é›£ â†’ ã€Œä»®æ‰•é‡‘ã€

ã€ã¹ãç­‰æ€§ãƒ«ãƒ¼ãƒ«ï¼ˆæœ€é‡è¦ï¼‰ã€‘
- åŒã˜ç”»åƒã«ã¯å¸¸ã«åŒã˜çµæœã‚’è¿”ã—ã¦ãã ã•ã„
- åº—åãŒé£²é£Ÿåº—ã§é‡‘é¡10,000å††æœªæº€ãªã‚‰ã€Œé£²é£Ÿè²»ã€ã‚’é¸æŠ
- è¿·ã£ãŸå ´åˆã¯ã€Œé£²é£Ÿè²»ã€ã‚’é¸æŠ

ã€å‡ºåŠ›å½¢å¼ã€‘
- JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ã¿å‡ºåŠ›
- ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ä¸è¦
- èª¬æ˜æ–‡ä¸è¦`;

        // APIå‘¼ã³å‡ºã—ï¼ˆç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼‰
        const result = await model.generateContent({
            contents: [{
                role: 'user',
                parts: [
                    {
                        inlineData: {
                            mimeType: mimeType,
                            data: imageBase64
                        }
                    },
                    {
                        text: prompt
                    }
                ]
            }]
        });

        // ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹é€ ã‚’ãƒ‡ãƒãƒƒã‚°
        console.log('ğŸ” [Debug] result.response:', JSON.stringify(result.response, null, 2).substring(0, 500));

        const responseText = result.response.candidates?.[0]?.content?.parts?.[0]?.text || '';
        console.log('ğŸ” [Debug] responseText length:', responseText.length);

        // ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’å–å¾—
        const usageMetadata = result.response.usageMetadata;
        if (usageMetadata) {
            console.log('ğŸ“Š [Vertex] ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡:', {
                promptTokenCount: usageMetadata.promptTokenCount,
                candidatesTokenCount: usageMetadata.candidatesTokenCount,
                totalTokenCount: usageMetadata.totalTokenCount,
                cachedContentTokenCount: usageMetadata.cachedContentTokenCount || 0
            });

            // Gemini 2.5 Flashæ–™é‡‘ã§å®Ÿã‚³ã‚¹ãƒˆè¨ˆç®—ï¼ˆ$1=Â¥150ï¼‰
            const cachedTokens = usageMetadata.cachedContentTokenCount || 0;
            const inputTokens = usageMetadata.promptTokenCount || 0;
            const outputTokens = usageMetadata.candidatesTokenCount || 0;

            // ãƒ¢ãƒ‡ãƒ«åˆ¥æ–™é‡‘å®šç¾©ï¼ˆVertex AIï¼‰
            const PRICING_FLASH = {
                name: 'Gemini 2.5 Flash',
                INPUT_NORMAL: 0.30 / 1_000_000,   // $0.30 per 1M tokens
                INPUT_CACHED: 0.03 / 1_000_000,   // $0.03 per 1M tokens (90% discount)
                OUTPUT: 2.50 / 1_000_000,         // $2.50 per 1M tokens
            };
            const PRICING_PRO = {
                name: 'Gemini 2.5 Pro',
                INPUT_NORMAL: 3.50 / 1_000_000,   // $3.50 per 1M tokens
                INPUT_CACHED: 0.875 / 1_000_000,  // $0.875 per 1M tokens (75% discount)
                OUTPUT: 10.50 / 1_000_000,        // $10.50 per 1M tokens
            };
            const EXCHANGE_RATE = 150;  // $1 = Â¥150

            // ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«ã«åŸºã¥ã„ã¦æ–™é‡‘é¸æŠ
            const PRICING = modelName.includes('pro') ? PRICING_PRO : PRICING_FLASH;

            // è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆãƒã‚¤ãƒŠã‚¹å€¤ã‚’é˜²æ­¢ï¼‰
            const costCache = cachedTokens * PRICING.INPUT_CACHED * EXCHANGE_RATE;
            const nonCachedTokens = Math.max(0, inputTokens - cachedTokens);
            const costInput = nonCachedTokens * PRICING.INPUT_NORMAL * EXCHANGE_RATE;
            const costOutput = outputTokens * PRICING.OUTPUT * EXCHANGE_RATE;
            const totalCost = costCache + costInput + costOutput;

            console.log(`ğŸ’° [Vertex] æ¨å®šã‚³ã‚¹ãƒˆ (${PRICING.name}):`, {
                'Cacheå…¥åŠ›': `Â¥${costCache.toFixed(4)} (${cachedTokens} tokens)`,
                'é€šå¸¸å…¥åŠ›': `Â¥${costInput.toFixed(4)} (${inputTokens - cachedTokens} tokens)`,
                'å‡ºåŠ›': `Â¥${costOutput.toFixed(4)} (${outputTokens} tokens)`,
                'åˆè¨ˆ': `Â¥${totalCost.toFixed(4)}`
            });
        }

        console.log(`âœ… [Vertex] APIå‘¼ã³å‡ºã—æˆåŠŸ`);

        return responseText;
    } catch (error) {
        console.error('âŒ [Vertex] APIå‘¼ã³å‡ºã—å¤±æ•—:', error);
        throw new Error(`Vertex AI call failed: ${error}`);
    }
}

/**
 * ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰JSONæŠ½å‡º
 *
 * Geminiã¯ ```json ... ``` å½¢å¼ã§è¿”ã™ã“ã¨ãŒå¤šã„
 *
 * @param responseText - ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆ
 * @returns JSON object
 */
function extractJSONFromResponse(responseText: string): any {
    // ãƒ‘ã‚¿ãƒ¼ãƒ³1: ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ (```json ... ```)
    const jsonCodeBlockMatch = responseText.match(/```json\s*\n([\s\S]*?)\n```/);
    if (jsonCodeBlockMatch) {
        try {
            return JSON.parse(jsonCodeBlockMatch[1]);
        } catch {
            // ãƒ‘ãƒ¼ã‚¹å¤±æ•—æ™‚ã¯æ¬¡ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã¸
        }
    }

    // ãƒ‘ã‚¿ãƒ¼ãƒ³2: é€šå¸¸ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ (``` ... ```)
    const codeBlockMatch = responseText.match(/```\s*\n([\s\S]*?)\n```/);
    if (codeBlockMatch) {
        try {
            return JSON.parse(codeBlockMatch[1]);
        } catch {
            // ãƒ‘ãƒ¼ã‚¹å¤±æ•—æ™‚ã¯æ¬¡ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã¸
        }
    }

    // ãƒ‘ã‚¿ãƒ¼ãƒ³3: ãƒ†ã‚­ã‚¹ãƒˆå†…ã®JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æ¢ã™
    const jsonObjectMatch = responseText.match(/\{[\s\S]*"category"[\s\S]*\}/);
    if (jsonObjectMatch) {
        try {
            return JSON.parse(jsonObjectMatch[0]);
        } catch {
            // ãƒ‘ãƒ¼ã‚¹å¤±æ•—æ™‚ã¯æ¬¡ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã¸
        }
    }

    // ãƒ‘ã‚¿ãƒ¼ãƒ³4: ç›´æ¥ãƒ‘ãƒ¼ã‚¹
    try {
        return JSON.parse(responseText);
    } catch {
        console.error('JSONè§£æå¤±æ•—ã€‚ãƒ¬ã‚¹ãƒãƒ³ã‚¹å†’é ­500æ–‡å­—:', responseText.substring(0, 500));
        throw new Error('Invalid JSON response from Vertex AI');
    }
}
